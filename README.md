# âš¡ ML-Based Bhopal Electricity Consumption Analysis

### End-to-End Data Analysis & Machine Learning Project (Google Colab)

---

## ğŸ“Œ Overview

This project presents a complete **data science and machine learning pipeline** to analyze and predict **electricity consumption patterns in Madhya Pradesh (Bhopal region)**.

Developed in **Google Colab using Python**, this project demonstrates:

* ğŸ“Š Data preprocessing & merging from multiple sources
* ğŸ“ˆ Exploratory Data Analysis (EDA)
* ğŸ” Feature correlation & distribution analysis
* ğŸ¤– Machine Learning preprocessing pipeline
* âš¡ Scalable and structured workflow

---

## ğŸ§  Key Highlights

âœ” Real-world dataset integration (weather + energy)
âœ” Advanced visualization techniques
âœ” Clean preprocessing pipeline using `ColumnTransformer`
âœ” Feature scaling using `StandardScaler`
âœ” Modular and reusable ML workflow

---

## ğŸ—ï¸ Project Workflow

### ğŸ”„ Step-by-Step Pipeline

```id="flow123"
1. Import Libraries
2. Mount Google Drive
3. Load Datasets (CSV + Excel)
4. Data Cleaning & Preprocessing
5. Merge Datasets on Date
6. Handle Missing Values
7. Exploratory Data Analysis (EDA)
8. Feature Engineering
9. Train-Test Split
10. Preprocessing Pipeline (Scaling)
11. Model Training (XGBoost)
12. Evaluation & Predictions
```

---

## ğŸ“¦ Libraries Used

```python
pandas, numpy
xgboost
matplotlib, seaborn
sklearn (metrics, preprocessing, model_selection)
```

---

## ğŸ“‚ Data Sources

* **Factor Data (Weather Data)** â†’ `Madhya_Pradesh.csv`
* **Energy Data** â†’ `energy.xlsx`

These datasets are merged on a common **date column** to create a unified dataset.

---

## ğŸ”— Data Merging Process

```python
factor_data['date'] = pd.to_datetime(factor_data['date'])
energy_data['Date'] = pd.to_datetime(energy_data['Date'])

energy_data = energy_data.rename(columns={'Date': 'date'})
merged_data = pd.merge(factor_data, energy_data, on='date', how='inner')
```

### âœ… Purpose:

* Align weather + energy data
* Enable feature-based prediction

---

## ğŸ§¹ Handling Missing Values

```python
for column in merged_data.columns:
    if merged_data[column].dtype != 'datetime64[ns]':
        if merged_data[column].isnull().any():
            merged_data[column].fillna(merged_data[column].mean(), inplace=True)
```

### âœ… Strategy:

* Replace missing values with **mean**
* Avoid modifying date column

---

## ğŸ“Š Exploratory Data Analysis (EDA)

### ğŸ“ˆ Time Series Visualization

* Daily Energy Consumption
* Peak Energy Demand

### ğŸ”¥ Correlation Heatmap

* Shows relationships between all numerical features
* Helps identify important predictors

### ğŸ“‰ Distribution Analysis

* Temperature
* Solar Radiation
* Cloud Cover
* UTCI

### ğŸ” Pair Plot

* Multi-variable relationship visualization

---

## ğŸ§  Feature Engineering

### Selected Important Features:

* Temperature (`2m_temperature_mean`)
* Solar Radiation
* Cloud Cover
* UTCI
* Energy Metrics (`daily_energy_met_MU`, `peak_met_MW`)

---

## âš™ï¸ Machine Learning Preprocessing Pipeline

### ğŸ¯ Objective

To standardize numerical features using a scalable and reusable pipeline.

---

### ğŸ”§ Step 1: Identify Numerical Features

```python
numerical_features = X.select_dtypes(include=np.number).columns.tolist()
```

---

### ğŸ”§ Step 2: Create ColumnTransformer Pipeline

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features)
    ],
    remainder='passthrough'
)
```

---

### ğŸ”§ Step 3: Apply Pipeline

```python
X_train_scaled_pipeline = preprocessor.fit_transform(X_train)
X_test_scaled_pipeline = preprocessor.transform(X_test)
```

---

### ğŸ”§ Step 4: Verify Output

```python
print(X_train_scaled_pipeline.shape)
print(X_test_scaled_pipeline.shape)

print(X_train_scaled_pipeline[:5])
```

---

## ğŸ“Š Why Use a Preprocessing Pipeline?

### âœ… Key Benefits

#### 1. ğŸ” Reusability

* Same preprocessing applied to training & testing data
* Avoids duplication of code

#### 2. ğŸ§  Consistency

* Prevents data leakage
* Ensures identical transformations

#### 3. âš¡ Efficiency

* Combines multiple preprocessing steps into one object

#### 4. ğŸ§© Scalability

* Easy to extend (add encoding, feature selection, etc.)

#### 5. ğŸš€ Production Ready

* Pipeline can be directly used in deployment

---

## ğŸ¤– Model (XGBoost)

The project uses:

```python
import xgboost as xgb
```

### Why XGBoost?

* High performance
* Handles complex relationships
* Works well with structured data

---

## ğŸ“ˆ Evaluation Metrics

* Mean Squared Error (MSE)
* Mean Absolute Error (MAE)
* RÂ² Score

---

## ğŸ“Š Visual Outputs

* Time series plots
* Correlation heatmap
* Feature distributions
* Pair plots

---

## âš¡ How to Run

### â–¶ï¸ Google Colab

1. Upload notebook
2. Mount Google Drive
3. Run all cells

---

### ğŸ’» Local Setup

```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost
```

---

## ğŸ“Š Use Cases

* âš¡ Electricity demand forecasting
* ğŸŒ¤ Weather impact analysis
* ğŸ“ˆ Energy optimization
* ğŸ§  Data science learning

---

## ğŸŒŸ Highlights

âœ” Multi-source dataset merging
âœ” Strong EDA foundation
âœ” Advanced preprocessing pipeline
âœ” Real-world ML problem solving
âœ” Clean and modular code

---

## ğŸ§© Future Improvements

* ğŸ“Š Add time-series models (LSTM, ARIMA)
* ğŸŒ Build web dashboard
* âš¡ Real-time prediction system
* ğŸ“ˆ Hyperparameter tuning
* ğŸ§  Deep learning models

---

## ğŸ‘¨â€ğŸ’» Author

**Your Name**

* Data Science & ML Enthusiast
* Passionate about solving real-world problems using AI

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

## ğŸ’¡ Final Note

This project demonstrates how combining **weather data + machine learning** can provide powerful insights into **electricity consumption patterns**.

A strong portfolio project for aspiring **Data Scientists & ML Engineers ğŸš€**

---
